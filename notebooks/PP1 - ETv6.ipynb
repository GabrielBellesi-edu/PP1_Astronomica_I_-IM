{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b616d-84e9-4312-9ee8-0533ca8d3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib scipy plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1ee1c-8695-438b-9737-2ece8a2aa35c",
   "metadata": {},
   "source": [
    "<h3>conversion.py</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0279ea8-6b8f-40df-a686-036191524e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion-v5.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def convertir_mpd_a_csv(ruta_mpd=\"../data/raw\",     \n",
    "                        ruta_salida=\"../data/interim/conversion\",\n",
    "                        filas_saltadas=29): \n",
    "    ruta_mpd = Path(ruta_mpd) # Ruta a los .mpd\n",
    "    ruta_csv = Path(ruta_salida) # Ruta donde guardar los .csv \n",
    "    ruta_csv.mkdir(exist_ok=True) # Crea la carpeta si no existe\n",
    "    \n",
    "    # Buscar todos los archivos .mpd\n",
    "    archivos_mpd = sorted(ruta_mpd.glob(\"mp*.riogrande.mpd\"))  \n",
    "    colspecs = [\n",
    "    (0, 11),     # Date (YYYY/MM/DD)\n",
    "    (12, 24),    # Time (hh:mm:ss.sss)\n",
    "    (25, 30),    # File ID (ej: 00RU0)\n",
    "    (31, 36),    # Rge\n",
    "    (37, 43),    # Ht\n",
    "    (44, 51),    # Vrad\n",
    "    (52, 58),    # delVr\n",
    "    (59, 65),    # Theta\n",
    "    (66, 73),    # Phi0\n",
    "    (75, 76),    # Ambig\n",
    "    (80, 85),    # Delphase\n",
    "    (89, 92),    # ant-pair\n",
    "    (99, 100),   # IREX\n",
    "    (102, 109),  # amax\n",
    "    (110, 114),  # Tau\n",
    "    (115, 120),  # vmet\n",
    "    (122, 127),  # snrdb\n",
    "    ]\n",
    "    for archivo in archivos_mpd:\n",
    "        # Notificacion de progreso. \n",
    "        print(f\"Convirtiendo: {archivo.name}\")\n",
    "\n",
    "        # Leer datos ignorando las primeras filas. Avisa al pandas que viene sin header\n",
    "        df = pd.read_fwf(archivo, skiprows=filas_saltadas, header=None, colspecs=colspecs)\n",
    "\n",
    "        # Convertir la columna de fecha al formato DD/MM/AAAA\n",
    "        df[0] = pd.to_datetime(df[0], format=\"%Y/%m/%d\").dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        # Nombre de archivo .csv en la nueva carpeta \n",
    "        nuevo_nombre = ruta_csv / (archivo.stem + \".csv\")\n",
    "\n",
    "        # Guardar como CSV con separador \";\" y decimal \",\" y sin agregar header\n",
    "        df.to_csv(nuevo_nombre, index=False, sep=\";\", decimal=\",\",header=False)\n",
    "    \n",
    "    # Confirmacion de proceso terminado. \n",
    "    print(\"✅ Proceso completado: todos los archivos han sido convertidos correctamente.\")\n",
    "\n",
    "convertir_mpd_a_csv()# MODIFICAR PARAMETROS SEGUN CORRESPONDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea2281-bff9-4a31-8329-856996eb3acc",
   "metadata": {},
   "source": [
    "<h2>transformacion.py</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ce703-41f5-401f-9237-f841f9d65c61",
   "metadata": {},
   "source": [
    "<h4>cambio el nombre de la funcion a transformacion.py</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dba77b-903a-40dc-a87b-a5cf5c7f1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def filtro_ambig(ruta_entrada=\"../data/interim/conversion\",\n",
    "           ruta_salida=\"../data/interim/transformacion\", \n",
    "           columna_objetivo=9, valor_permitido=1, #De la columna 9 (ambig) Elimina todos los registros distintos a 1\n",
    "           columnas_a_eliminar=[2, 9, 12]): #Elimina las columnas 2 (file) 9 (ambig) y 12 (IREX)\n",
    "           \n",
    "    \n",
    "    ruta_entrada = Path(ruta_entrada)\n",
    "    ruta_salida = Path(ruta_salida)\n",
    "    ruta_salida.mkdir(exist_ok=True)\n",
    "\n",
    "    archivos_csv = sorted(ruta_entrada.glob(\"*.csv\"))\n",
    "\n",
    "    for archivo in archivos_csv:\n",
    "        print(f\"Procesando: {archivo.name}\")\n",
    "\n",
    "        # Leer el CSV sin encabezado\n",
    "        df = pd.read_csv(archivo, sep=\";\", header=None, decimal=\",\")\n",
    "\n",
    "        # Filtrar por ambigüedad\n",
    "        df_filtrado = df[df[columna_objetivo] == valor_permitido]\n",
    "\n",
    "        # Eliminar columnas especificadas\n",
    "        df_resultado = df_filtrado.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "        # Guardar resultado\n",
    "        nuevo_nombre = ruta_salida / archivo.name\n",
    "        df_resultado.to_csv(nuevo_nombre, index=False, sep=\";\", decimal=\",\", header=False)\n",
    "\n",
    "    print(\"✅ Proceso de filtrado y depuración completado correctamente.\")\n",
    "filtro_ambig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61611ff-b992-4cfb-b06f-9efdc8c94e43",
   "metadata": {},
   "source": [
    "<h2>Filtrado por RGE 100-130</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab92932-df59-4b05-b88e-adec0f4ce7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def filtro_rge(ruta_entrada=\"../data/interim/transformacion\",\n",
    "                   ruta_salida=\"../data/interim/filtrado\",\n",
    "                   indice_rge=2,\n",
    "                   rge_min=100,\n",
    "                   rge_max=130):\n",
    "    \n",
    "    ruta_entrada = Path(ruta_entrada)\n",
    "    ruta_salida = Path(ruta_salida)\n",
    "    ruta_salida.mkdir(exist_ok=True)\n",
    "\n",
    "    archivos_csv = sorted(ruta_entrada.glob(\"*.csv\"))\n",
    "\n",
    "    for archivo in archivos_csv:\n",
    "        print(f\"Filtrando por Rge: {archivo.name}\")\n",
    "\n",
    "        # Leer archivo filtrado previamente\n",
    "        df = pd.read_csv(archivo, sep=\";\", header=None, decimal=\",\")\n",
    "\n",
    "        # Aplicar filtro por Rge entre 100 y 130 inclusive\n",
    "        df_filtrado = df[(df[indice_rge] >= rge_min) & (df[indice_rge] <= rge_max)]\n",
    "\n",
    "        # Guardar archivo filtrado\n",
    "        nuevo_nombre = ruta_salida / archivo.name\n",
    "        df_filtrado.to_csv(nuevo_nombre, index=False, sep=\";\", decimal=\",\", header=False)\n",
    "\n",
    "    print(\"✅ Filtrado por Rge completado correctamente.\")\n",
    "\n",
    "filtro_rge()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978cc80-cc11-4960-8d40-4ed71380f6d4",
   "metadata": {},
   "source": [
    "<h2>Transformacion.py</h2>\n",
    "<h4>Elimino la funcion transformacion.py (No vamos a usar el valor amaxT y reordenamos la funcion)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5aa171-ab84-4fb2-b915-6c0fc989f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #transformacion.py\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# def transformar_archivos_csv(\n",
    "#         ruta_entrada=\"INDICE_DE_MASA/csv/filtrado/rge\",\n",
    "#         ruta_salida=\"INDICE_DE_MASA/csv/transformado\"):\n",
    "#     ruta_entrada = Path(ruta_entrada)\n",
    "#     ruta_salida = Path(ruta_salida)\n",
    "#     ruta_salida.mkdir(exist_ok=True)\n",
    "\n",
    "#     archivos_csv = sorted(ruta_entrada.glob(\"*.csv\"))\n",
    "\n",
    "#     for archivo in archivos_csv:\n",
    "#         print(f\"Procesando: {archivo.name}\")\n",
    "        \n",
    "#         # Cargar el CSV sin encabezado, usando ; como separador y , como decimal\n",
    "#         df = pd.read_csv(archivo, sep=\";\", decimal=\",\", header=None)\n",
    "\n",
    "#         # Verificar que haya al menos 14 columnas\n",
    "#         if df.shape[1] < 14:\n",
    "#             print(f\"⚠️ {archivo.name} tiene menos de 14 columnas. Se omite.\")\n",
    "#             continue\n",
    "\n",
    "#         # Nueva columna: columna 10 - columna 13 (índices)\n",
    "#         nueva_columna = df.iloc[:, 10] - df.iloc[:, 13]\n",
    "        \n",
    "#         # Agregar la nueva columna al final\n",
    "#         df[df.shape[1]] = nueva_columna\n",
    "\n",
    "#         # Guardar el nuevo archivo, sin encabezado\n",
    "#         salida = ruta_salida / archivo.name\n",
    "#         df.to_csv(salida, sep=\";\", decimal=\",\", index=False, header=False)\n",
    "    \n",
    "#     print(\"✅ Transformación completa.\")\n",
    "\n",
    "# transformar_archivos_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a925fc-1204-47f8-9fd2-8cca8f527d9d",
   "metadata": {},
   "source": [
    "<h2>consolidacion.py</h2>\n",
    "<h4>modifique las rutas.\n",
    "elimino la columna antes agregada de amaxT (amax - snrdb)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bb411-32aa-44a7-9d00-a2da3154c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidacion.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def consolidar_csv(ruta_entrada=\"../data/interim/filtrado\", ruta_salida=\"../data/processed/2024_consolidado.csv\"): # Rutas predeterminadas\n",
    "    ruta_entrada = Path(ruta_entrada)\n",
    "    # Buscar todos los archivos con extensión .csv dentro de esa carpeta\n",
    "    archivos_csv = sorted(ruta_entrada.glob(\"*.csv\"))\n",
    "    \n",
    "    # ruta_salida = Path(ruta_salida)\n",
    "    # ruta_salida.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Lista de nombres de columnas, ya que los archivos CSV individuales no tienen encabezado\n",
    "    columnas = [\n",
    "        \"Date\", \"Time\", \"Rge\", \"Ht\", \"Vrad\", \"delVr\",\n",
    "        \"Theta\", \"Phi0\", \"Delphase\", \"ant-pair\",\n",
    "        \"amax\", \"Tau\", \"vmet\", \"snrdb\"\n",
    "    ]\n",
    "    \n",
    "    # Lista vacía para acumular los DataFrames de cada archivo\n",
    "    dataframes = []\n",
    "    \n",
    "    # Iterar sobre cada archivo CSV individual\n",
    "    for archivo in archivos_csv:\n",
    "        # Notificacion de progreso.\n",
    "        print(f\"Leyendo: {archivo.name}\")\n",
    "\n",
    "        # Leer el archivo sin encabezado, asigna los nombres de columnas definidas arriba y usando ; como separador y , como decimal\n",
    "        df = pd.read_csv(archivo, header=None, names=columnas, sep=\";\", decimal=\",\")\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Unir todos los DataFrames\n",
    "    df_total = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "   \n",
    "    # Guardar\n",
    "    df_total.to_csv(ruta_salida, index=False, sep=\";\",decimal=\",\")\n",
    "    \n",
    "    # Mensaje de confirmación al finalizar\n",
    "    print(\"✅ Consolidación completada sin errores de columnas.\")\n",
    "\n",
    "consolidar_csv() # MODIFICAR PARAMETROS SEGUN CORRESPONDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f79e93-1f77-408b-a33f-70b55e6774eb",
   "metadata": {},
   "source": [
    "<h2>elimino todo salvo amax</h2>\n",
    "se modifico la funcion para elimnar todo, salvo amax  (en lugar de amaxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae84fa75-9a0a-476b-a15c-53be6a3d8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo guardado solo con la última columna.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dejar_solo_ultima_columna(ruta_entrada, ruta_salida):\n",
    "    # Leer el CSV original (con encabezado, separador ; y decimal ,)\n",
    "    df = pd.read_csv(ruta_entrada, sep=\";\", decimal=\",\")\n",
    "\n",
    "    # Seleccionar solo la última columna (por posición)\n",
    "    ultima_columna = df.iloc[:, [10]]  # [-1] mantiene el DataFrame en lugar de Series\n",
    "\n",
    "    # Guardar sin encabezado y sin índice\n",
    "    ultima_columna.to_csv(ruta_salida, sep=\";\", decimal=\",\", index=False, header=False)\n",
    "\n",
    "    print(\"✅ Archivo guardado solo con la última columna.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "dejar_solo_ultima_columna(\"../data/processed/2024_consolidado.csv\", \"../data/processed/2024_consolidado_amax.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
